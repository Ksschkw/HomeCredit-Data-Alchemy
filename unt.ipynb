{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "530b1cea-f417-476d-8c1a-9b54e58db7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# it was written on the medium to Refer to :- https://www.kaggle.com/rinnqd/reduce-memory-usage\n",
    "\n",
    "def reduce_memory_usage(df):\n",
    "  \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a56824-14d8-46f2-b644-f73b28eddfb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 92.38 MB\n",
      "Decreased by 67.7%\n",
      "Memory usage of dataframe is 222.62 MB\n",
      "Memory usage after optimization is: 112.95 MB\n",
      "Decreased by 49.3%\n",
      "Memory usage of dataframe is 624.85 MB\n",
      "Memory usage after optimization is: 338.46 MB\n",
      "Decreased by 45.8%\n",
      "Memory usage of dataframe is 471.48 MB\n",
      "Memory usage after optimization is: 309.01 MB\n",
      "Decreased by 34.5%\n",
      "Memory usage of dataframe is 830.41 MB\n",
      "Memory usage after optimization is: 311.40 MB\n",
      "Decreased by 62.5%\n",
      "Memory usage of dataframe is 610.43 MB\n",
      "Memory usage after optimization is: 238.45 MB\n",
      "Decreased by 60.9%\n",
      "Memory usage of dataframe is 673.88 MB\n",
      "Memory usage after optimization is: 289.33 MB\n",
      "Decreased by 57.1%\n",
      "PRINTING OUT ALL FEATURES IN THE DATASET\n",
      "\n",
      "Features/Columns in train_data include: \n",
      " ['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
      "\n",
      "Features/Columns in bureau_data include: \n",
      " ['SK_ID_CURR', 'SK_ID_BUREAU', 'CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT', 'AMT_CREDIT_SUM_OVERDUE', 'CREDIT_TYPE', 'DAYS_CREDIT_UPDATE', 'AMT_ANNUITY']\n",
      "\n",
      "Features/Columns in bureau_balance include: \n",
      " ['SK_ID_BUREAU', 'MONTHS_BALANCE', 'STATUS']\n",
      "\n",
      "Features/Columns in prev_app include: \n",
      " ['SK_ID_PREV', 'SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY', 'RATE_DOWN_PAYMENT', 'RATE_INTEREST_PRIMARY', 'RATE_INTEREST_PRIVILEGED', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS', 'DAYS_DECISION', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'SELLERPLACE_AREA', 'NAME_SELLER_INDUSTRY', 'CNT_PAYMENT', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL']\n",
      "\n",
      "Features/Columns in installments include: \n",
      " ['SK_ID_PREV', 'SK_ID_CURR', 'NUM_INSTALMENT_VERSION', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT', 'AMT_INSTALMENT', 'AMT_PAYMENT']\n",
      "\n",
      "Features/Columns in pos_cash include: \n",
      " ['SK_ID_PREV', 'SK_ID_CURR', 'MONTHS_BALANCE', 'CNT_INSTALMENT', 'CNT_INSTALMENT_FUTURE', 'NAME_CONTRACT_STATUS', 'SK_DPD', 'SK_DPD_DEF']\n",
      "\n",
      "Features/Columns in credit_card include: \n",
      " ['SK_ID_PREV', 'SK_ID_CURR', 'MONTHS_BALANCE', 'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL', 'AMT_DRAWINGS_ATM_CURRENT', 'AMT_DRAWINGS_CURRENT', 'AMT_DRAWINGS_OTHER_CURRENT', 'AMT_DRAWINGS_POS_CURRENT', 'AMT_INST_MIN_REGULARITY', 'AMT_PAYMENT_CURRENT', 'AMT_PAYMENT_TOTAL_CURRENT', 'AMT_RECEIVABLE_PRINCIPAL', 'AMT_RECIVABLE', 'AMT_TOTAL_RECEIVABLE', 'CNT_DRAWINGS_ATM_CURRENT', 'CNT_DRAWINGS_CURRENT', 'CNT_DRAWINGS_OTHER_CURRENT', 'CNT_DRAWINGS_POS_CURRENT', 'CNT_INSTALMENT_MATURE_CUM', 'NAME_CONTRACT_STATUS', 'SK_DPD', 'SK_DPD_DEF']\n"
     ]
    }
   ],
   "source": [
    "train_data = reduce_memory_usage(pd.read_csv(\"application_train.csv\"))\n",
    "bureau_data = reduce_memory_usage(pd.read_csv('bureau.csv'))\n",
    "bureau_balance = reduce_memory_usage(pd.read_csv('bureau_balance.csv'))\n",
    "prev_app = reduce_memory_usage(pd.read_csv('previous_application.csv'))\n",
    "installments = reduce_memory_usage(pd.read_csv('installments_payments.csv'))\n",
    "pos_cash = reduce_memory_usage(pd.read_csv('POS_CASH_balance.csv'))\n",
    "credit_card = reduce_memory_usage(pd.read_csv('credit_card_balance.csv'))\n",
    "\n",
    "print(\"PRINTING OUT ALL FEATURES IN THE DATASET\")\n",
    "print(\"\\nFeatures/Columns in train_data include: \\n\", train_data.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in bureau_data include: \\n\", bureau_data.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in bureau_balance include: \\n\", bureau_balance.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in prev_app include: \\n\", prev_app.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in installments include: \\n\", installments.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in pos_cash include: \\n\", pos_cash.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in credit_card include: \\n\", credit_card.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "653fd79e-fdad-4c0b-a2b7-32540334d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Memory usage of dataframe is 222.62 MB\n",
      "Memory usage after optimization is: 112.95 MB\n",
      "Decreased by 49.3%\n",
      "Memory usage of dataframe is 624.85 MB\n",
      "Memory usage after optimization is: 338.46 MB\n",
      "Decreased by 45.8%\n",
      "Memory usage of dataframe is 471.48 MB\n",
      "Memory usage after optimization is: 309.01 MB\n",
      "Decreased by 34.5%\n",
      "Memory usage of dataframe is 830.41 MB\n",
      "Memory usage after optimization is: 311.40 MB\n",
      "Decreased by 62.5%\n",
      "Memory usage of dataframe is 673.88 MB\n",
      "Memory usage after optimization is: 289.33 MB\n",
      "Decreased by 57.1%\n",
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 92.38 MB\n",
      "Decreased by 67.7%\n",
      "Creating balance_history.csv...\n",
      "Creating transaction_history.csv...\n",
      "Creating loan_application_history.csv...\n",
      "Creating loan_repayment_history.csv...\n",
      "Creating customer_bio_data.csv...\n",
      "All 5 clean datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "bureau = reduce_memory_usage(pd.read_csv('bureau.csv'))\n",
    "bureau_balance = reduce_memory_usage(pd.read_csv('bureau_balance.csv'))\n",
    "prev_app = reduce_memory_usage(pd.read_csv('previous_application.csv'))\n",
    "installments = reduce_memory_usage(pd.read_csv('installments_payments.csv'))\n",
    "credit_card = reduce_memory_usage(pd.read_csv('credit_card_balance.csv'))\n",
    "application_train = reduce_memory_usage(pd.read_csv('application_train.csv'))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. CREDIT BUREAU HISTORY (from bureau + bureau_balance)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Creating balance_history.csv...\")\n",
    "\n",
    "# Merge bureau with its balance data\n",
    "status_agg = pd.get_dummies(bureau_balance[['SK_ID_BUREAU', 'STATUS']], columns=['STATUS'])\n",
    "status_agg = status_agg.groupby('SK_ID_BUREAU', as_index=False).sum()\n",
    "\n",
    "# Create clean dataset\n",
    "balance_history = bureau.merge(\n",
    "    status_agg, \n",
    "    on='SK_ID_BUREAU', \n",
    "    how='left'\n",
    ")[[\n",
    "    'SK_ID_CURR', 'SK_ID_BUREAU', 'CREDIT_ACTIVE', 'CREDIT_CURRENCY',\n",
    "    'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'AMT_CREDIT_SUM',\n",
    "    'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_OVERDUE',\n",
    "    'STATUS_0', 'STATUS_1', 'STATUS_2', 'STATUS_3', 'STATUS_4', 'STATUS_5', 'STATUS_C', 'STATUS_X'\n",
    "]].rename(columns={\n",
    "    'SK_ID_CURR': 'customer_id',\n",
    "    'SK_ID_BUREAU': 'credit_bureau_id',\n",
    "    'CREDIT_ACTIVE': 'credit_status',\n",
    "    'CREDIT_CURRENCY': 'credit_currency',\n",
    "    'DAYS_CREDIT': 'days_since_credit_start',\n",
    "    'CREDIT_DAY_OVERDUE': 'current_overdue_days',\n",
    "    'AMT_CREDIT_SUM': 'total_credit_amount',\n",
    "    'AMT_CREDIT_SUM_DEBT': 'current_debt_amount',\n",
    "    'AMT_CREDIT_SUM_OVERDUE': 'current_overdue_amount',\n",
    "    'STATUS_0': 'months_on_time',\n",
    "    'STATUS_1': 'months_1_30_dpd',\n",
    "    'STATUS_2': 'months_31_60_dpd',\n",
    "    'STATUS_3': 'months_61_90_dpd',\n",
    "    'STATUS_4': 'months_91_120_dpd',\n",
    "    'STATUS_5': 'months_120_plus_dpd',\n",
    "    'STATUS_C': 'months_closed',\n",
    "    'STATUS_X': 'months_no_info'\n",
    "})\n",
    "\n",
    "balance_history.to_csv('balance_history.csv', index=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. CREDIT CARD TRANSACTIONS (from credit_card_balance)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Creating transaction_history.csv...\")\n",
    "\n",
    "transaction_history = credit_card[[\n",
    "    'SK_ID_CURR', 'SK_ID_PREV', 'MONTHS_BALANCE',\n",
    "    'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL',\n",
    "    'AMT_DRAWINGS_CURRENT', 'CNT_DRAWINGS_CURRENT',\n",
    "    'AMT_PAYMENT_CURRENT', 'AMT_PAYMENT_TOTAL_CURRENT',\n",
    "    'SK_DPD', 'SK_DPD_DEF'\n",
    "]].rename(columns={\n",
    "    'SK_ID_CURR': 'customer_id',\n",
    "    'SK_ID_PREV': 'previous_loan_id',\n",
    "    'MONTHS_BALANCE': 'months_since_transaction',\n",
    "    'AMT_BALANCE': 'current_balance',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': 'credit_limit',\n",
    "    'AMT_DRAWINGS_CURRENT': 'total_spent_amount',\n",
    "    'CNT_DRAWINGS_CURRENT': 'transaction_count',\n",
    "    'AMT_PAYMENT_CURRENT': 'minimum_payment_amount',\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': 'total_payment_amount',\n",
    "    'SK_DPD': 'days_past_due',\n",
    "    'SK_DPD_DEF': 'days_past_due_90_plus'\n",
    "})\n",
    "\n",
    "transaction_history.to_csv('transaction_history.csv', index=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. PREVIOUS LOAN APPLICATIONS (from previous_application)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Creating loan_application_history.csv...\")\n",
    "\n",
    "# Preserve TARGET from original training data\n",
    "target_map = application_train[['SK_ID_CURR', 'TARGET']].set_index('SK_ID_CURR')['TARGET']\n",
    "\n",
    "loan_application_history = prev_app[[\n",
    "    'SK_ID_CURR', 'SK_ID_PREV', 'NAME_CONTRACT_TYPE',\n",
    "    'AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT',\n",
    "    'DAYS_DECISION', 'NAME_CONTRACT_STATUS',\n",
    "    'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON'\n",
    "]].rename(columns={\n",
    "    'SK_ID_CURR': 'customer_id',\n",
    "    'SK_ID_PREV': 'previous_loan_id',\n",
    "    'NAME_CONTRACT_TYPE': 'loan_type',\n",
    "    'AMT_ANNUITY': 'annuity_amount',\n",
    "    'AMT_APPLICATION': 'requested_amount',\n",
    "    'AMT_CREDIT': 'approved_amount',\n",
    "    'DAYS_DECISION': 'days_since_decision',\n",
    "    'NAME_CONTRACT_STATUS': 'application_status',\n",
    "    'NAME_PAYMENT_TYPE': 'payment_type',\n",
    "    'CODE_REJECT_REASON': 'reject_reason_code'\n",
    "})\n",
    "\n",
    "# Add repayment capability flag\n",
    "loan_application_history['repayment_capability'] = loan_application_history['customer_id'].map(target_map)\n",
    "loan_application_history.to_csv('loan_application_history.csv', index=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. LOAN REPAYMENT HISTORY (from installments_payments)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Creating loan_repayment_history.csv...\")\n",
    "\n",
    "loan_repayment_history = installments[[\n",
    "    'SK_ID_CURR', 'SK_ID_PREV', \n",
    "    'DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT',\n",
    "    'AMT_INSTALMENT', 'AMT_PAYMENT'\n",
    "]].rename(columns={\n",
    "    'SK_ID_CURR': 'customer_id',\n",
    "    'SK_ID_PREV': 'previous_loan_id',\n",
    "    'DAYS_INSTALMENT': 'due_date_days',\n",
    "    'DAYS_ENTRY_PAYMENT': 'payment_date_days',\n",
    "    'AMT_INSTALMENT': 'due_amount',\n",
    "    'AMT_PAYMENT': 'paid_amount'\n",
    "})\n",
    "\n",
    "loan_repayment_history.to_csv('loan_repayment_history.csv', index=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. CUSTOMER DEMOGRAPHICS (from application_train)\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Creating customer_bio_data.csv...\")\n",
    "\n",
    "customer_bio_data = application_train[[\n",
    "    'SK_ID_CURR', 'CODE_GENDER', \n",
    "    'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', \n",
    "    'CNT_CHILDREN', 'AMT_INCOME_TOTAL', \n",
    "    'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "    'DAYS_BIRTH', 'DAYS_EMPLOYED', 'OCCUPATION_TYPE',\n",
    "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3'\n",
    "]].rename(columns={\n",
    "    'SK_ID_CURR': 'customer_id',\n",
    "    'CODE_GENDER': 'gender',\n",
    "    'FLAG_OWN_CAR': 'owns_car_flag',\n",
    "    'FLAG_OWN_REALTY': 'owns_property_flag',\n",
    "    'CNT_CHILDREN': 'children_count',\n",
    "    'AMT_INCOME_TOTAL': 'annual_income',\n",
    "    'NAME_EDUCATION_TYPE': 'education_level',\n",
    "    'NAME_FAMILY_STATUS': 'family_status',\n",
    "    'DAYS_BIRTH': 'age_in_days',\n",
    "    'DAYS_EMPLOYED': 'employment_days',\n",
    "    'OCCUPATION_TYPE': 'occupation',\n",
    "    'EXT_SOURCE_1': 'external_score_1',\n",
    "    'EXT_SOURCE_2': 'external_score_2',\n",
    "    'EXT_SOURCE_3': 'external_score_3'\n",
    "})\n",
    "\n",
    "customer_bio_data.to_csv('customer_bio_data.csv', index=False)\n",
    "\n",
    "print(\"All 5 clean datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59b31928-9ab3-4e3b-8941-b4361d468ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING NEW DATASET..\n",
      "Memory usage of dataframe is 222.62 MB\n",
      "Memory usage after optimization is: 91.67 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 322.29 MB\n",
      "Memory usage after optimization is: 128.18 MB\n",
      "Decreased by 60.2%\n",
      "Memory usage of dataframe is 140.17 MB\n",
      "Memory usage after optimization is: 89.20 MB\n",
      "Decreased by 36.4%\n",
      "Memory usage of dataframe is 622.81 MB\n",
      "Memory usage after optimization is: 259.50 MB\n",
      "Decreased by 58.3%\n",
      "Memory usage of dataframe is 32.85 MB\n",
      "Memory usage after optimization is: 20.24 MB\n",
      "Decreased by 38.4%\n",
      "PRINTING OUT ALL NEW FEATURES IN THE DATASET\n",
      "\n",
      "Features/Columns in balance_history include:  ['customer_id', 'credit_bureau_id', 'credit_status', 'credit_currency', 'days_since_credit_start', 'current_overdue_days', 'total_credit_amount', 'current_debt_amount', 'current_overdue_amount', 'months_on_time', 'months_1_30_dpd', 'months_31_60_dpd', 'months_61_90_dpd', 'months_91_120_dpd', 'months_120_plus_dpd', 'months_closed', 'months_no_info']\n",
      "\n",
      "Features/Columns in transaction_history include:  ['customer_id', 'previous_loan_id', 'months_since_transaction', 'current_balance', 'credit_limit', 'total_spent_amount', 'transaction_count', 'minimum_payment_amount', 'total_payment_amount', 'days_past_due', 'days_past_due_90_plus']\n",
      "\n",
      "Features/Columns in loan_application_history include:  ['customer_id', 'previous_loan_id', 'loan_type', 'annuity_amount', 'requested_amount', 'approved_amount', 'days_since_decision', 'application_status', 'payment_type', 'reject_reason_code', 'repayment_capability']\n",
      "\n",
      "Features/Columns in loan_repayment_history include:  ['customer_id', 'previous_loan_id', 'due_date_days', 'payment_date_days', 'due_amount', 'paid_amount']\n",
      "\n",
      "Features/Columns in customer_bio_data include:  ['customer_id', 'gender', 'owns_car_flag', 'owns_property_flag', 'children_count', 'annual_income', 'education_level', 'family_status', 'age_in_days', 'employment_days', 'occupation', 'external_score_1', 'external_score_2', 'external_score_3']\n"
     ]
    }
   ],
   "source": [
    "print(\"LOADING NEW DATASET..\")\n",
    "balance_history = reduce_memory_usage(pd.read_csv(\"balance_history.csv\"))\n",
    "transaction_history = reduce_memory_usage(pd.read_csv(\"transaction_history.csv\"))\n",
    "loan_application_history = reduce_memory_usage(pd.read_csv(\"loan_application_history.csv\"))\n",
    "loan_repayment_history = reduce_memory_usage(pd.read_csv(\"loan_repayment_history.csv\"))\n",
    "customer_bio_data = reduce_memory_usage(pd.read_csv(\"customer_bio_data.csv\"))\n",
    "\n",
    "print(\"PRINTING OUT ALL NEW FEATURES IN THE DATASET\")\n",
    "print(\"\\nFeatures/Columns in balance_history include: \", balance_history.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in transaction_history include: \", transaction_history.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in loan_application_history include: \", loan_application_history.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in loan_repayment_history include: \", loan_repayment_history.columns.tolist())\n",
    "print(\"\\nFeatures/Columns in customer_bio_data include: \", customer_bio_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "290048b1-4369-4235-8e81-0e6f93eee6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing datasets...\n",
      "Optimization complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOptimizing datasets...\")\n",
    "\n",
    "# --- Credit Bureau History Fix ---\n",
    "# Convert status columns to int16\n",
    "status_cols = [col for col in balance_history.columns if col.startswith('months_')]\n",
    "balance_history[status_cols] = balance_history[status_cols].fillna(0).astype(np.int16)\n",
    "\n",
    "# --- Credit Card Transactions Optimization ---\n",
    "# Convert to absolute values and optimize\n",
    "for col in ['total_spent_amount', 'minimum_payment_amount', 'total_payment_amount']:\n",
    "    transaction_history[col] = transaction_history[col].abs().astype(np.float32)\n",
    "\n",
    "# --- Loan Repayment Optimization ---\n",
    "# Calculate payment delay\n",
    "loan_repayment_history['payment_delay_days'] = (\n",
    "    loan_repayment_history['payment_date_days'] - loan_repayment_history['due_date_days']\n",
    ").astype(np.float32)\n",
    "\n",
    "# --- Customer Demographics Optimization ---\n",
    "# Convert employment days to years\n",
    "customer_bio_data['employment_years'] = (\n",
    "    -customer_bio_data['employment_days'] / 365\n",
    ").clip(0, 50).round(1).astype(np.float16)\n",
    "customer_bio_data.drop('employment_days', axis=1, inplace=True)\n",
    "\n",
    "# Save optimized datasets\n",
    "balance_history.to_csv('balance_history.csv', index=False)\n",
    "transaction_history.to_csv('transaction_history.csv', index=False)\n",
    "loan_application_history.to_csv('loan_application_history.csv', index=False)\n",
    "loan_repayment_history.to_csv('loan_repayment_history.csv', index=False)\n",
    "customer_bio_data.to_csv('customer_bio_data.csv', index=False)\n",
    "\n",
    "print(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9303f67e-4928-4c23-9dad-f0465c3b3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating mobile_usage_data.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 307511/307511 [02:28<00:00, 2069.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 77.42 MB\n",
      "Memory usage after optimization is: 20.53 MB\n",
      "Decreased by 73.5%\n",
      "Mobile data generation complete!\n",
      "All 6 datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nGenerating mobile_usage_data.csv...\")\n",
    "\n",
    "# Load necessary data\n",
    "customer_bio_data = pd.read_csv('customer_bio_data.csv')\n",
    "loan_app_history = pd.read_csv('loan_application_history.csv')\n",
    "\n",
    "# Get target values per customer\n",
    "target_per_customer = loan_app_history.groupby('customer_id')['repayment_capability'].first().reset_index()\n",
    "mobile_data = customer_bio_data[['customer_id']].merge(\n",
    "    target_per_customer, on='customer_id', how='left'\n",
    ")\n",
    "\n",
    "# Fill any missing targets with 0 (non-default)\n",
    "mobile_data['repayment_capability'] = mobile_data['repayment_capability'].fillna(0)\n",
    "\n",
    "# Set observation period parameters\n",
    "OBSERVATION_DAYS = 30\n",
    "SECONDS_PER_DAY = 86400\n",
    "NIGHT_HOURS = (22, 6)\n",
    "WORK_HOURS = (9, 17)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_customer_mobile_data(target):\n",
    "    \"\"\"Generate realistic mobile usage data for a single customer\"\"\"\n",
    "    data = {}\n",
    "    target = int(target)\n",
    "    \n",
    "    # Core call metrics with risk-based adjustments\n",
    "    base_call_count = max(10, np.random.poisson(80 - 25*target))\n",
    "    call_duration_base = max(30, 180 - 60*target)\n",
    "    \n",
    "    data['total_calls_count'] = base_call_count\n",
    "    data['total_call_duration_seconds'] = call_duration_base * base_call_count * abs(np.random.lognormal(0, 0.2))\n",
    "    \n",
    "    # Incoming/outgoing split\n",
    "    outgoing_ratio = np.clip(0.4 + 0.3*target, 0.1, 0.9)\n",
    "    data['outgoing_calls_count'] = int(base_call_count * outgoing_ratio)\n",
    "    data['incoming_calls_count'] = base_call_count - data['outgoing_calls_count']\n",
    "    \n",
    "    # SMS metrics\n",
    "    base_sms_count = max(5, np.random.poisson(50 + 30*target))\n",
    "    data['total_sms_count'] = base_sms_count\n",
    "    sms_out_ratio = np.clip(0.3 + 0.4*target, 0.1, 0.9)\n",
    "    data['outgoing_sms_count'] = int(base_sms_count * sms_out_ratio)\n",
    "    data['incoming_sms_count'] = base_sms_count - data['outgoing_sms_count']\n",
    "    \n",
    "    # Contact diversity\n",
    "    data['unique_contacts_called'] = max(1, np.random.poisson(35 - 15*target))\n",
    "    data['unique_sms_contacts'] = max(1, np.random.poisson(30 - 12*target))\n",
    "    \n",
    "    # Airtime behavior (high-risk: smaller, more frequent topups)\n",
    "    topup_count = max(1, np.random.poisson(8 + 12*target))\n",
    "    avg_topup = np.random.uniform(3, 10) if target == 1 else np.random.uniform(8, 25)\n",
    "    \n",
    "    data['airtime_topup_count'] = topup_count\n",
    "    data['airtime_topup_total_amount'] = avg_topup * topup_count\n",
    "    data['average_topup_amount'] = avg_topup\n",
    "    \n",
    "    # App usage patterns\n",
    "    data['app_usage_count'] = max(10, np.random.poisson(100 + 50*target))\n",
    "    data['app_usage_duration_seconds'] = abs(np.random.lognormal(6 + 0.5*target, 0.3)) * 3600\n",
    "    data['unique_apps_used'] = max(1, np.random.poisson(25 - 8*target))\n",
    "    \n",
    "    # Time-based patterns (riskier behavior at night)\n",
    "    night_call_ratio = np.clip(0.1 + 0.25*target, 0.05, 0.8)\n",
    "    night_app_ratio = np.clip(0.15 + 0.3*target, 0.05, 0.8)\n",
    "    \n",
    "    data['night_time_calls_count'] = int(base_call_count * night_call_ratio)\n",
    "    data['day_time_calls_count'] = base_call_count - data['night_time_calls_count']\n",
    "    data['night_time_app_usage_seconds'] = data['app_usage_duration_seconds'] * night_app_ratio\n",
    "    \n",
    "    # Behavioral variability (higher for defaulters)\n",
    "    data['call_duration_variance'] = 1000 + 2500*target * abs(np.random.chisquare(2))\n",
    "    data['sms_count_variance'] = 50 + 150*target * abs(np.random.exponential(1))\n",
    "    \n",
    "    # Interaction patterns\n",
    "    data['average_inter_call_time_seconds'] = OBSERVATION_DAYS * SECONDS_PER_DAY / (base_call_count + 1)\n",
    "    data['average_inter_sms_time_seconds'] = OBSERVATION_DAYS * SECONDS_PER_DAY / (base_sms_count + 1)\n",
    "    \n",
    "    # Communication ratios\n",
    "    data['call_out_in_ratio'] = (\n",
    "        data['outgoing_calls_count'] / data['incoming_calls_count']\n",
    "    ) if data['incoming_calls_count'] > 0 else 1.0\n",
    "    \n",
    "    data['sms_out_in_ratio'] = (\n",
    "        data['outgoing_sms_count'] / data['incoming_sms_count']\n",
    "    ) if data['incoming_sms_count'] > 0 else 1.0\n",
    "    \n",
    "    # Call duration extremes\n",
    "    data['max_call_duration_seconds'] = call_duration_base * abs(np.random.lognormal(1.5, 0.3))\n",
    "    data['min_call_duration_seconds'] = max(1, call_duration_base * abs(np.random.lognormal(-1, 0.4)))\n",
    "    \n",
    "    # Weekend patterns (riskier behavior on weekends)\n",
    "    weekend_ratio = np.clip(0.3 + 0.4*target, 0.1, 0.7)\n",
    "    data['weekend_call_count'] = int(base_call_count * weekend_ratio)\n",
    "    data['weekday_call_count'] = base_call_count - data['weekend_call_count']\n",
    "    \n",
    "    # Daily averages\n",
    "    data['daily_calls_average'] = base_call_count / OBSERVATION_DAYS\n",
    "    data['daily_sms_average'] = base_sms_count / OBSERVATION_DAYS\n",
    "    \n",
    "    # App session metrics\n",
    "    session_ratio = min(0.99, max(0.01, np.random.beta(1, 5 - 3*target)))\n",
    "    data['longest_app_session_seconds'] = session_ratio * data['app_usage_duration_seconds']\n",
    "    \n",
    "    # App categories with risk-based preferences\n",
    "    app_categories = ['Finance', 'Productivity', 'Communication', \n",
    "                     'Entertainment', 'Social', 'Gaming', 'Utilities']\n",
    "    app_probs_low = [0.25, 0.20, 0.15, 0.10, 0.10, 0.10, 0.10]\n",
    "    app_probs_high = [0.10, 0.10, 0.15, 0.25, 0.15, 0.15, 0.10]\n",
    "    \n",
    "    probs = app_probs_high if target == 1 else app_probs_low\n",
    "    data['frequent_app_category'] = np.random.choice(app_categories, p=probs)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate mobile data for all customers\n",
    "rows = []\n",
    "for idx, row in tqdm(mobile_data.iterrows(), total=len(mobile_data)):\n",
    "    customer_data = generate_customer_mobile_data(row['repayment_capability'])\n",
    "    customer_data['customer_id'] = row['customer_id']\n",
    "    rows.append(customer_data)\n",
    "\n",
    "mobile_df = pd.DataFrame(rows)\n",
    "mobile_df = reduce_memory_usage(mobile_df)\n",
    "mobile_df.to_csv('mobile_usage_data.csv', index=False)\n",
    "\n",
    "print(\"Mobile data generation complete!\")\n",
    "print(\"All 6 datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fd49e-4b00-405f-8056-ece030206aab",
   "metadata": {},
   "source": [
    "# CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "399bea76-b5bd-4e41-a97a-00570f27a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading customer_bio_data.csv...\n",
      "Initial shape: (307511, 14)\n",
      "Initial missing values:\n",
      "customer_id                0\n",
      "gender                     0\n",
      "owns_car_flag              0\n",
      "owns_property_flag         0\n",
      "children_count             0\n",
      "annual_income              0\n",
      "education_level            0\n",
      "family_status              0\n",
      "age_in_days                0\n",
      "occupation             96391\n",
      "external_score_1      173378\n",
      "external_score_2         660\n",
      "external_score_3       60965\n",
      "employment_years           0\n",
      "dtype: int64\n",
      "\n",
      "=== Occupation Handling ===\n",
      "Added occupation risk categories\n",
      "\n",
      "=== External Scores Handling ===\n",
      "\n",
      "=== Gender Handling ===\n",
      "Median income by gender:\n",
      "gender\n",
      "F    135000.0\n",
      "M    180000.0\n",
      "Name: annual_income, dtype: float64\n",
      "\n",
      "=== Income Categorization ===\n",
      "\n",
      "=== Education Handling ===\n",
      "\n",
      "=== Outlier Treatment ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_customer_bio_data.csv\n",
      "\n",
      "Loading balance_history.csv...\n",
      "Initial shape: (1716428, 17)\n",
      "Initial missing values:\n",
      "customer_id                     0\n",
      "credit_bureau_id                0\n",
      "credit_status                   0\n",
      "credit_currency                 0\n",
      "days_since_credit_start         0\n",
      "current_overdue_days            0\n",
      "total_credit_amount            13\n",
      "current_debt_amount        257669\n",
      "current_overdue_amount          0\n",
      "months_on_time                  0\n",
      "months_1_30_dpd                 0\n",
      "months_31_60_dpd                0\n",
      "months_61_90_dpd                0\n",
      "months_91_120_dpd               0\n",
      "months_120_plus_dpd             0\n",
      "months_closed                   0\n",
      "months_no_info                  0\n",
      "dtype: int64\n",
      "\n",
      "=== Currency Handling ===\n",
      "\n",
      "=== Debt Handling ===\n",
      "\n",
      "=== Delinquency Features ===\n",
      "\n",
      "=== Outlier Treatment ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_balance_history.csv\n",
      "\n",
      "Loading transaction_history.csv...\n",
      "Initial shape: (3840312, 11)\n",
      "Initial missing values:\n",
      "customer_id                      0\n",
      "previous_loan_id                 0\n",
      "months_since_transaction         0\n",
      "current_balance                  0\n",
      "credit_limit                     0\n",
      "total_spent_amount               0\n",
      "transaction_count                0\n",
      "minimum_payment_amount      767988\n",
      "total_payment_amount             0\n",
      "days_past_due                    0\n",
      "days_past_due_90_plus            0\n",
      "dtype: int64\n",
      "\n",
      "=== Payment Handling ===\n",
      "\n",
      "=== Risk Features ===\n",
      "\n",
      "=== Outlier Treatment ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_transaction_history.csv\n",
      "\n",
      "Loading loan_application_history.csv...\n",
      "Initial shape: (1670214, 11)\n",
      "Initial missing values:\n",
      "customer_id                  0\n",
      "previous_loan_id             0\n",
      "loan_type                    0\n",
      "annuity_amount          372235\n",
      "requested_amount             0\n",
      "approved_amount              1\n",
      "days_since_decision          0\n",
      "application_status           0\n",
      "payment_type                 0\n",
      "reject_reason_code           0\n",
      "repayment_capability    256513\n",
      "dtype: int64\n",
      "\n",
      "=== Handling Missing Values ===\n",
      "\n",
      "=== Risk Features ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_loan_application_history.csv\n",
      "\n",
      "Loading loan_repayment_history.csv...\n",
      "Initial shape: (13605401, 7)\n",
      "Initial missing values:\n",
      "customer_id              0\n",
      "previous_loan_id         0\n",
      "due_date_days            0\n",
      "payment_date_days     2905\n",
      "due_amount               0\n",
      "paid_amount           2905\n",
      "payment_delay_days    2905\n",
      "dtype: int64\n",
      "\n",
      "=== Handling Missing Payments ===\n",
      "\n",
      "=== Payment Behavior ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_loan_repayment_history.csv\n",
      "\n",
      "Loading mobile_usage_data.csv...\n",
      "Initial shape: (307511, 33)\n",
      "Initial missing values:\n",
      "total_calls_count                  0\n",
      "total_call_duration_seconds        0\n",
      "outgoing_calls_count               0\n",
      "incoming_calls_count               0\n",
      "total_sms_count                    0\n",
      "outgoing_sms_count                 0\n",
      "incoming_sms_count                 0\n",
      "unique_contacts_called             0\n",
      "unique_sms_contacts                0\n",
      "airtime_topup_count                0\n",
      "airtime_topup_total_amount         0\n",
      "average_topup_amount               0\n",
      "app_usage_count                    0\n",
      "app_usage_duration_seconds         0\n",
      "unique_apps_used                   0\n",
      "night_time_calls_count             0\n",
      "day_time_calls_count               0\n",
      "night_time_app_usage_seconds       0\n",
      "call_duration_variance             0\n",
      "sms_count_variance                 0\n",
      "average_inter_call_time_seconds    0\n",
      "average_inter_sms_time_seconds     0\n",
      "call_out_in_ratio                  0\n",
      "sms_out_in_ratio                   0\n",
      "max_call_duration_seconds          0\n",
      "min_call_duration_seconds          0\n",
      "weekend_call_count                 0\n",
      "weekday_call_count                 0\n",
      "daily_calls_average                0\n",
      "daily_sms_average                  0\n",
      "longest_app_session_seconds        0\n",
      "frequent_app_category              0\n",
      "customer_id                        0\n",
      "dtype: int64\n",
      "\n",
      "=== Mobile Risk Score ===\n",
      "\n",
      "=== Outlier Capping ===\n",
      "\n",
      "✅ Cleaned data saved: cleaned_mobile_usage_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------- CUSTOMER BIO DATA CLEANING -------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading customer_bio_data.csv...\")\n",
    "bio_data = pd.read_csv('customer_bio_data.csv')\n",
    "print(f\"Initial shape: {bio_data.shape}\")\n",
    "print(f\"Initial missing values:\\n{bio_data.isnull().sum()}\")\n",
    "\n",
    "# 1. Occupation-specific handling (from EDA)\n",
    "print(\"\\n=== Occupation Handling ===\")\n",
    "bio_data['occupation'] = bio_data['occupation'].fillna('Unknown')\n",
    "\n",
    "# Create occupation risk categories based on EDA\n",
    "high_risk_occupations = ['Low-skill Laborers', 'Drivers', 'Waiters/barmen staff', 'Security staff', 'Cooking staff']\n",
    "bio_data['occupation_risk'] = bio_data['occupation'].apply(\n",
    "    lambda x: 'High' if x in high_risk_occupations else ('Medium' if x != 'Unknown' else 'Unknown')\n",
    ")\n",
    "print(\"Added occupation risk categories\")\n",
    "\n",
    "# 2. External scores handling\n",
    "print(\"\\n=== External Scores Handling ===\")\n",
    "for i in range(1, 4):\n",
    "    col = f'external_score_{i}'\n",
    "    bio_data[col] = bio_data[col].fillna(bio_data[col].median())\n",
    "    \n",
    "    # Create risk categories based on EDA\n",
    "    bio_data[f'{col}_risk'] = pd.cut(\n",
    "        bio_data[col],\n",
    "        bins=[0, 0.4, 0.6, 1],\n",
    "        labels=['High Risk', 'Medium Risk', 'Low Risk'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "# 3. Gender cleaning (from EDA)\n",
    "print(\"\\n=== Gender Handling ===\")\n",
    "bio_data = bio_data[bio_data['gender'].isin(['M', 'F'])]  # Remove XNA\n",
    "gender_income_median = bio_data.groupby('gender')['annual_income'].median()\n",
    "print(f\"Median income by gender:\\n{gender_income_median}\")\n",
    "\n",
    "# 4. Income categorization (from EDA)\n",
    "print(\"\\n=== Income Categorization ===\")\n",
    "income_bins = [0, 100000, 200000, 300000, 500000, float('inf')]\n",
    "income_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "bio_data['income_category'] = pd.cut(bio_data['annual_income'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "# 5. Education handling (from EDA)\n",
    "print(\"\\n=== Education Handling ===\")\n",
    "education_risk = {\n",
    "    'Lower secondary': 'High',\n",
    "    'Secondary / secondary special': 'Medium',\n",
    "    'Incomplete higher': 'Medium',\n",
    "    'Higher education': 'Low',\n",
    "    'Academic degree': 'Very Low'\n",
    "}\n",
    "bio_data['education_risk'] = bio_data['education_level'].map(education_risk)\n",
    "\n",
    "# 6. Outlier treatment\n",
    "print(\"\\n=== Outlier Treatment ===\")\n",
    "bio_data['children_count'] = bio_data['children_count'].clip(upper=6)  # Based on EDA\n",
    "bio_data['annual_income'] = bio_data['annual_income'].clip(upper=472500)  # 99th percentile\n",
    "\n",
    "# 7. Save cleaned data\n",
    "bio_data.to_csv('cleaned_customer_bio_data.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_customer_bio_data.csv\")\n",
    "\n",
    "# ------------------- BALANCE HISTORY CLEANING -------------------\n",
    "print(\"\\nLoading balance_history.csv...\")\n",
    "balance = pd.read_csv('balance_history.csv')\n",
    "print(f\"Initial shape: {balance.shape}\")\n",
    "print(f\"Initial missing values:\\n{balance.isnull().sum()}\")\n",
    "\n",
    "# 1. Currency-specific handling (from EDA)\n",
    "print(\"\\n=== Currency Handling ===\")\n",
    "balance['credit_currency'] = balance['credit_currency'].fillna('currency_1')\n",
    "\n",
    "# Create currency risk based on EDA default rates\n",
    "currency_risk = {\n",
    "    'currency_1': 'Medium',\n",
    "    'currency_2': 'Low',\n",
    "    'currency_3': 'High',\n",
    "    'currency_4': 'Very Low'\n",
    "}\n",
    "balance['currency_risk'] = balance['credit_currency'].map(currency_risk)\n",
    "\n",
    "# 2. Debt handling\n",
    "print(\"\\n=== Debt Handling ===\")\n",
    "balance['current_debt_amount'] = balance['current_debt_amount'].fillna(0)\n",
    "balance['current_overdue_amount'] = balance['current_overdue_amount'].fillna(0)\n",
    "\n",
    "# 3. Delinquency features\n",
    "print(\"\\n=== Delinquency Features ===\")\n",
    "del_cols = [c for c in balance.columns if c.startswith('months_') and '_dpd' in c]\n",
    "balance['total_delinquent_months'] = balance[del_cols].sum(axis=1)\n",
    "balance['severe_delinquency'] = (balance['months_91_120_dpd'] + balance['months_120_plus_dpd'] > 0).astype(int)\n",
    "\n",
    "# 4. Outlier treatment\n",
    "print(\"\\n=== Outlier Treatment ===\")\n",
    "for col in ['total_credit_amount', 'current_debt_amount']:\n",
    "    balance[col] = balance[col].clip(upper=balance[col].quantile(0.95))\n",
    "\n",
    "# 5. Save cleaned data\n",
    "balance.to_csv('cleaned_balance_history.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_balance_history.csv\")\n",
    "\n",
    "# ------------------- TRANSACTION HISTORY CLEANING -------------------\n",
    "print(\"\\nLoading transaction_history.csv...\")\n",
    "trans = pd.read_csv('transaction_history.csv')\n",
    "print(f\"Initial shape: {trans.shape}\")\n",
    "print(f\"Initial missing values:\\n{trans.isnull().sum()}\")\n",
    "\n",
    "# 1. Payment handling\n",
    "print(\"\\n=== Payment Handling ===\")\n",
    "trans['minimum_payment_amount'] = trans['minimum_payment_amount'].fillna(0)\n",
    "\n",
    "# 2. Risk features\n",
    "print(\"\\n=== Risk Features ===\")\n",
    "trans['credit_utilization'] = trans['current_balance'] / trans['credit_limit'].replace(0, np.nan)\n",
    "trans['missed_payment'] = (trans['days_past_due'] > 0).astype(int)\n",
    "trans['severe_delinquency'] = (trans['days_past_due_90_plus'] > 0).astype(int)\n",
    "\n",
    "# 3. Outlier treatment\n",
    "print(\"\\n=== Outlier Treatment ===\")\n",
    "for col in ['total_spent_amount', 'credit_limit', 'current_balance']:\n",
    "    trans[col] = trans[col].clip(upper=trans[col].quantile(0.99))\n",
    "\n",
    "# 4. Save cleaned data\n",
    "trans.to_csv('cleaned_transaction_history.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_transaction_history.csv\")\n",
    "\n",
    "# ------------------- LOAN APPLICATION HISTORY CLEANING -------------------\n",
    "print(\"\\nLoading loan_application_history.csv...\")\n",
    "loans = pd.read_csv('loan_application_history.csv')\n",
    "print(f\"Initial shape: {loans.shape}\")\n",
    "print(f\"Initial missing values:\\n{loans.isnull().sum()}\")\n",
    "\n",
    "# 1. Handle missing values\n",
    "print(\"\\n=== Handling Missing Values ===\")\n",
    "loans['reject_reason_code'] = loans['reject_reason_code'].fillna('Approved')\n",
    "loans['annuity_amount'] = loans['annuity_amount'].fillna(loans['annuity_amount'].median())\n",
    "loans['approved_amount'] = loans['approved_amount'].fillna(loans['requested_amount'])\n",
    "\n",
    "# 2. Risk features\n",
    "print(\"\\n=== Risk Features ===\")\n",
    "loans['approval_ratio'] = loans['approved_amount'] / loans['requested_amount'].replace(0, np.nan)\n",
    "loans['was_rejected'] = (loans['application_status'] == 'Refused').astype(int)\n",
    "\n",
    "# 3. Save cleaned data\n",
    "loans.to_csv('cleaned_loan_application_history.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_loan_application_history.csv\")\n",
    "\n",
    "# ------------------- LOAN REPAYMENT HISTORY CLEANING -------------------\n",
    "print(\"\\nLoading loan_repayment_history.csv...\")\n",
    "repayments = pd.read_csv('loan_repayment_history.csv')\n",
    "print(f\"Initial shape: {repayments.shape}\")\n",
    "print(f\"Initial missing values:\\n{repayments.isnull().sum()}\")\n",
    "\n",
    "# 1. Handle missing payments\n",
    "print(\"\\n=== Handling Missing Payments ===\")\n",
    "repayments['payment_date_days'] = repayments['payment_date_days'].fillna(repayments['due_date_days'])\n",
    "repayments['paid_amount'] = repayments['paid_amount'].fillna(0)  # Assume no payment\n",
    "\n",
    "# 2. Payment behavior features\n",
    "print(\"\\n=== Payment Behavior ===\")\n",
    "repayments['payment_delay'] = repayments['payment_date_days'] - repayments['due_date_days']\n",
    "repayments['is_late'] = (repayments['payment_delay'] > 0).astype(int)\n",
    "repayments['payment_completeness'] = repayments['paid_amount'] / repayments['due_amount'].replace(0, np.nan)\n",
    "\n",
    "# 3. Save cleaned data\n",
    "repayments.to_csv('cleaned_loan_repayment_history.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_loan_repayment_history.csv\")\n",
    "\n",
    "# ------------------- MOBILE USAGE DATA CLEANING -------------------\n",
    "print(\"\\nLoading mobile_usage_data.csv...\")\n",
    "mobile = pd.read_csv('mobile_usage_data.csv')\n",
    "print(f\"Initial shape: {mobile.shape}\")\n",
    "print(f\"Initial missing values:\\n{mobile.isnull().sum()}\")\n",
    "\n",
    "# 1. Risk score based on EDA\n",
    "print(\"\\n=== Mobile Risk Score ===\")\n",
    "mobile['night_ratio'] = mobile['night_time_calls_count'] / (mobile['day_time_calls_count'] + 1)\n",
    "mobile['gaming_entertainment'] = mobile['frequent_app_category'].isin(['Gaming', 'Entertainment']).astype(int)\n",
    "mobile['risk_score'] = (\n",
    "    0.4 * mobile['night_ratio'] +\n",
    "    0.3 * (mobile['airtime_topup_count'] > 10).astype(int) +\n",
    "    0.3 * mobile['gaming_entertainment']\n",
    ")\n",
    "\n",
    "# 2. Outlier treatment\n",
    "print(\"\\n=== Outlier Capping ===\")\n",
    "for col in ['app_usage_duration_seconds', 'total_call_duration_seconds', 'longest_app_session_seconds']:\n",
    "    mobile[col] = mobile[col].clip(upper=mobile[col].quantile(0.99))\n",
    "\n",
    "# 3. Save cleaned data\n",
    "mobile.to_csv('cleaned_mobile_usage_data.csv', index=False)\n",
    "print(\"\\n✅ Cleaned data saved: cleaned_mobile_usage_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be49dbd-dd54-425e-9564-2560a8e5e585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
